Proposal: Develop deep learning solutions to the problem of leaf segmentation and counting in plant phenotyping applications.

Abstract: The goal of this project is to develop deep neural network (DNN) models to perform end to end automated leaf counting using 2D RGB images (other imaging modalities are optional and will be explained in detail later). The purpose of this project is for the students to implement the current state of the art models for this task and to investigate ways in which to improve the current results experimenting with various network architectures and techniques learned in class.
Motivation: The field of phenomics has exploded within the precision agriculture community as new methods to improve crop yield and agricultural efficiency are becoming necessary to keep up with growing worldwide food demands [1]. High throughput plant phenotyping has seen a growing interest within multi-disciplinary research communities from agriculture to plant science to computer science [2]. Plant phenotyping is the identification of effects on the phenotype (i.e., the plant appearance and performance) as a result of genotype differences (i.e., differences in the genetic code) and the environmental conditions to which a plant has been exposed. According to the Food and Agriculture Organization of the United Nations, large-scale experiments in plant phenotyping are a key factor in meeting the agricultural needs of the future to feed the world and provide biomass for energy, while using less water, land, and fertilizer under a constantly evolving environment due to climate change. Currently, a major bottleneck in phenotyping research is image analysis algorithms [3]. One of the major phenotypes that provides insight into the health, growth progress, and future yield of a crop is leaf count, for this reason much research into automated leaf counting has been undertaken.

Background and Project Description: Leaf counting algorithms can be categorized into two main research directions: counting using multi-instance segmentation [4, 5] and counting directly as a nonlinear regression task [6-8]. With [5] being the state of the art in the instance segmentation technique and [7] being the state of the art in direct modeling of leaf count. [8] seems to have achieved even better results than [7] while also utilizing other imaging modalities and allowing for more flexibility and better generalizability of the model. The student should feel free to pursue whatever research direction/technique they feel seems the most interesting and has the greatest potential for results. This project is similar in style and scope to the leaf segmentation (LSC) and leaf counting (LCC) challenges held by the IPPN and CVPPP which also provides a full dataset for use in research of both tasks [9]. Many of the papers and research on these tasks were generated in response to the 2015 and 2017 challenges.

Data: The data for this project is provided at [9]. It consists of RGB images of tobacco plants and arabidopsis plants. Tobacco images were collected using a camera which contained in its field of view a single plant. Arabidopsis images were collected using a camera with a larger field of view encompassing many plants, which were cropped. The images released are either from mutants or wild types and have been taken in a span of several days. Plant images are encoded as tiff files. All images were hand labelled to obtain ground truth masks for each leaf in the scene. These masks are image files encoded in PNG where each segmented leaf is identified with a unique integer value, starting from 1, where 0 is background. For the counting problem,
 
annotations are provided in the form of a png image where each leaf center is denoted by a single pixel. Additionally a CSV file with image name and number of leaves is provided. If the students wish to replicate the results of [8] using multi-modality data, the specifics of that dataset and where to find the data can be found in the original paper.

References:
1.	Houle, D., Govindaraju, D. R., & Omholt, S. (2010). Phenomics: the next challenge. Nature reviews genetics, 11(12), 855.
2.	Fahlgren, N., Gehan, M. A., & Baxter, I. (2015). Lights, camera, action: high-throughput plant phenotyping is ready for a close-up. Current opinion in plant biology, 24, 93-99.
3.	Minervini, M., Scharr, H., & Tsaftaris, S. A. (2015). Image analysis: the new bottleneck in plant phenotyping [applications corner]. IEEE signal processing magazine, 32(4), 126-131.
4.	Ren, M., & Zemel, R. S. (2017). End-to-end instance segmentation with recurrent attention. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 6656-6664).
5.	Romera-Paredes B., Torr P.H.S. (2016) Recurrent Instance Segmentation. In: Leibe B., Matas J., Sebe N., Welling M. (eds) Computer Vision – ECCV 2016. ECCV 2016. Lecture Notes in Computer Science, vol 9910. Springer, Cham
6.	Aich, S., & Stavness, I. (2017). Leaf counting with deep convolutional and deconvolutional networks. In Proceedings of the IEEE International Conference on Computer Vision (pp. 2080- 2089).
7.	Ubbens, J. R., & Stavness, I. (2017). Deep plant phenomics: a deep learning platform for complex plant phenotyping tasks. Frontiers in plant science, 8, 1190.
8.	Giuffrida, M. V., Doerner, P., & Tsaftaris, S. A. (2018). Pheno‐Deep Counter: a unified and versatile deep learning architecture for leaf counting. The Plant Journal, 96(4), 880-890.
9.	Computer Vision Problems in Plant Phenotyping (CVPPP). (n.d.). Retrieved from https://www.plant-phenotyping.org/CVPPP2017
